{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3bafad84",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import gc\n",
    "import os\n",
    "import torch\n",
    "import random   \n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from copy import copy\n",
    "from tqdm import tqdm\n",
    "from torch.optim import Adam, SGD\n",
    "from sklearn.metrics import log_loss,mean_squared_error\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db0f6786",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "82ed998a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>season</th>\n",
       "      <th>team_score</th>\n",
       "      <th>opp_score</th>\n",
       "      <th>is_home</th>\n",
       "      <th>numot</th>\n",
       "      <th>team_fgm</th>\n",
       "      <th>team_fga</th>\n",
       "      <th>team_fgm3</th>\n",
       "      <th>team_fga3</th>\n",
       "      <th>team_ftm</th>\n",
       "      <th>...</th>\n",
       "      <th>opp_or</th>\n",
       "      <th>opp_dr</th>\n",
       "      <th>opp_ast</th>\n",
       "      <th>opp_to</th>\n",
       "      <th>opp_stl</th>\n",
       "      <th>opp_blk</th>\n",
       "      <th>opp_pf</th>\n",
       "      <th>team_name</th>\n",
       "      <th>opp_name</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2003</td>\n",
       "      <td>68</td>\n",
       "      <td>62</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "      <td>58</td>\n",
       "      <td>3</td>\n",
       "      <td>14</td>\n",
       "      <td>11</td>\n",
       "      <td>...</td>\n",
       "      <td>10</td>\n",
       "      <td>22</td>\n",
       "      <td>8</td>\n",
       "      <td>18</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>Oklahoma</td>\n",
       "      <td>2002-11-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2003</td>\n",
       "      <td>70</td>\n",
       "      <td>63</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>26</td>\n",
       "      <td>62</td>\n",
       "      <td>8</td>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>20</td>\n",
       "      <td>25</td>\n",
       "      <td>7</td>\n",
       "      <td>12</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>16</td>\n",
       "      <td>Memphis</td>\n",
       "      <td>Syracuse</td>\n",
       "      <td>2002-11-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2003</td>\n",
       "      <td>62</td>\n",
       "      <td>68</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>53</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>16</td>\n",
       "      <td>...</td>\n",
       "      <td>14</td>\n",
       "      <td>24</td>\n",
       "      <td>13</td>\n",
       "      <td>23</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>Oklahoma</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>2002-11-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2003</td>\n",
       "      <td>63</td>\n",
       "      <td>70</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>67</td>\n",
       "      <td>6</td>\n",
       "      <td>24</td>\n",
       "      <td>9</td>\n",
       "      <td>...</td>\n",
       "      <td>15</td>\n",
       "      <td>28</td>\n",
       "      <td>16</td>\n",
       "      <td>13</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>18</td>\n",
       "      <td>Syracuse</td>\n",
       "      <td>Memphis</td>\n",
       "      <td>2002-11-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2003</td>\n",
       "      <td>55</td>\n",
       "      <td>81</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>46</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>12</td>\n",
       "      <td>...</td>\n",
       "      <td>12</td>\n",
       "      <td>24</td>\n",
       "      <td>12</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>18</td>\n",
       "      <td>E Washington</td>\n",
       "      <td>Wisconsin</td>\n",
       "      <td>2002-11-15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   season  team_score  opp_score  is_home  numot  team_fgm  team_fga  \\\n",
       "0    2003          68         62        0      0        27        58   \n",
       "1    2003          70         63        0      0        26        62   \n",
       "2    2003          62         68        0      0        22        53   \n",
       "3    2003          63         70        0      0        24        67   \n",
       "4    2003          55         81       -1      0        20        46   \n",
       "\n",
       "   team_fgm3  team_fga3  team_ftm  ...  opp_or  opp_dr  opp_ast  opp_to  \\\n",
       "0          3         14        11  ...      10      22        8      18   \n",
       "1          8         20        10  ...      20      25        7      12   \n",
       "2          2         10        16  ...      14      24       13      23   \n",
       "3          6         24         9  ...      15      28       16      13   \n",
       "4          3         11        12  ...      12      24       12       9   \n",
       "\n",
       "   opp_stl  opp_blk  opp_pf     team_name   opp_name        date  \n",
       "0        9        2      20       Alabama   Oklahoma  2002-11-14  \n",
       "1        8        6      16       Memphis   Syracuse  2002-11-14  \n",
       "2        7        1      22      Oklahoma    Alabama  2002-11-14  \n",
       "3        4        4      18      Syracuse    Memphis  2002-11-14  \n",
       "4        9        3      18  E Washington  Wisconsin  2002-11-15  \n",
       "\n",
       "[5 rows x 34 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## https://github.com/JeffSackmann/tennis_wta\n",
    "\n",
    "DATA_PATH = 'D://Medium'\n",
    "os.listdir(DATA_PATH)\n",
    "\n",
    "def load_data():\n",
    "    return pd.read_csv(os.path.join(DATA_PATH, 'ncaam_sample_data.csv'))\n",
    "\n",
    "data = load_data()\n",
    "data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b5593bb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def feature_eng(df):\n",
    "    ## need match id. And going to only do one row per game, shuffled between perspective of winner and loser\n",
    "    df['team_A'] = df[['team_name','opp_name']].copy().apply(lambda x: sorted([x.team_name, x.opp_name])[0],axis=1)\n",
    "    df['match_id'] = df['date'].copy().astype(str)+'_'+df['team_A'].copy()\n",
    "    df = df.sample(frac=1)\n",
    "    df = df.drop_duplicates(subset=['match_id'], keep='first')\n",
    "    df = df.drop('team_A',axis=1)\n",
    "    df = df.sort_values(by='date').reset_index(drop=True)\n",
    "    \n",
    "    targets = ['score_diff_pct','total_reb_pct','score_total']\n",
    "    stats = ['score_diff_pct','oreb_pct','dreb_pct','fgm3_diff_pct','ftm_diff_pct','score_total','blk_pct_diff','ast_pct_diff','to_pct_diff', 'agg_pct_diff']\n",
    "    ## just mirror stats\n",
    "    opp_stats = ['opp_'+stat for stat in stats]\n",
    "    meta = ['is_home','days_rest', 'opp_days_rest']\n",
    "    \n",
    "    ## For NN, good for everything to be on same scale\n",
    "    ## in my first attempt i divided score diff by score total, etc. I think standard scaler might work better\n",
    "    df['score_diff_pct'] = (df['team_score'].copy()-df['opp_score'].copy())/(df['team_score'].copy()+df['opp_score'].copy())\n",
    "    df['oreb_pct'] = (df['team_or'].copy()-df['opp_dr'].copy())/(df['team_or'].copy()+df['opp_dr'].copy())\n",
    "    df['dreb_pct'] = (df['team_dr'].copy()-df['opp_or'].copy())/(df['team_dr'].copy()+df['opp_or'].copy())\n",
    "    df['total_reb_pct'] = ((df['team_or'].copy()+df['team_dr'].copy())-(df['opp_dr'].copy()+df['opp_or'].copy()))/((df['team_or'].copy()+df['team_dr'].copy())+(df['opp_dr'].copy()+df['opp_or'].copy()))\n",
    "    df['fgm3_diff_pct'] = (df['team_fgm3'].copy()-df['opp_fgm3'].copy())/(df['team_fgm3'].copy()+df['opp_fgm3'].copy())\n",
    "    df['ftm_diff_pct'] = (df['team_ftm'].copy()-df['opp_ftm'].copy())/(df['team_ftm'].copy()+df['opp_ftm'].copy())\n",
    "    df['score_total'] = (df['team_score'].copy()+df['opp_score'].copy())/265\n",
    "    df['blk_pct_diff'] = (df['team_blk'].copy()-df['opp_blk'].copy())/(df['team_blk'].copy()+df['opp_blk'].copy())\n",
    "    df['ast_pct_diff'] = (df['team_ast'].copy()-df['opp_ast'].copy())/(df['team_ast'].copy()+df['opp_ast'].copy())\n",
    "    df['to_pct_diff'] = (df['team_to'].copy()-df['opp_to'].copy())/(df['team_to'].copy()+df['opp_to'].copy())\n",
    "    df['agg_pct_diff'] = ((df['team_stl'].copy()+df['team_pf'].copy())-(df['opp_stl'].copy()+df['opp_pf'].copy()))/((df['team_stl'].copy()+df['team_pf'].copy())+(df['opp_stl'].copy()+df['opp_pf'].copy()))\n",
    "    \n",
    "    df['opp_score_diff_pct'] = -1*(df['team_score'].copy()-df['opp_score'].copy())/(df['team_score'].copy()+df['opp_score'].copy())\n",
    "    ## or and d reb swap \n",
    "    df['opp_dreb_pct'] = -1*(df['team_or'].copy()-df['opp_dr'].copy())/(df['team_or'].copy()+df['opp_dr'].copy())\n",
    "    df['opp_oreb_pct'] = -1*(df['team_dr'].copy()-df['opp_or'].copy())/(df['team_dr'].copy()+df['opp_or'].copy())\n",
    "    ##\n",
    "    df['opp_total_reb_pct'] = -1*((df['team_or'].copy()+df['team_dr'].copy())-(df['opp_dr'].copy()+df['opp_or'].copy()))/((df['team_or'].copy()+df['team_dr'].copy())+(df['opp_dr'].copy()+df['opp_or'].copy()))\n",
    "    df['opp_fgm3_diff_pct'] = -1*(df['team_fgm3'].copy()-df['opp_fgm3'].copy())/(df['team_fgm3'].copy()+df['opp_fgm3'].copy())\n",
    "    df['opp_ftm_diff_pct'] = -1*(df['team_ftm'].copy()-df['opp_ftm'].copy())/(df['team_ftm'].copy()+df['opp_ftm'].copy())\n",
    "    df['opp_score_total'] = -1*(df['team_score'].copy()+df['opp_score'].copy())/265\n",
    "    df['opp_blk_pct_diff'] = -1*(df['team_blk'].copy()-df['opp_blk'].copy())/(df['team_blk'].copy()+df['opp_blk'].copy())\n",
    "    df['opp_ast_pct_diff'] = -1*(df['team_ast'].copy()-df['opp_ast'].copy())/(df['team_ast'].copy()+df['opp_ast'].copy())\n",
    "    df['opp_to_pct_diff'] = -1*(df['team_to'].copy()-df['opp_to'].copy())/(df['team_to'].copy()+df['opp_to'].copy())\n",
    "    df['opp_agg_pct_diff'] = -1*((df['team_stl'].copy()+df['team_pf'].copy())-(df['opp_stl'].copy()+df['opp_pf'].copy()))/((df['team_stl'].copy()+df['team_pf'].copy())+(df['opp_stl'].copy()+df['opp_pf'].copy()))\n",
    "    \n",
    "    df['date'] = pd.to_datetime(df['date'].copy())\n",
    "    df['last_played'] = df.groupby(['team_name'])['date'].transform('shift')\n",
    "    df['last_played'] = df['last_played'].fillna(df['date'].copy()-pd.Timedelta(days=42))\n",
    "    df['opp_last_played'] = df.groupby(['opp_name'])['date'].transform('shift')\n",
    "    df['opp_last_played'] = df['opp_last_played'].fillna(df['date'].copy()-pd.Timedelta(days=42))\n",
    "    df['days_rest'] = ((df['date'].copy()-df['last_played'].copy()).dt.days)/365\n",
    "    df['opp_days_rest'] = ((df['date'].copy()-df['opp_last_played'].copy()).dt.days)/365\n",
    "    df = df.drop(columns=['last_played','opp_last_played'])\n",
    "    \n",
    "    ## only a handful, mostly blocks \n",
    "    df[stats] = df[stats].fillna(0.5)\n",
    "    df[opp_stats] = df[opp_stats].fillna(0.5)\n",
    "    \n",
    "    df['result'] = np.where(df['team_score'].copy()>df['opp_score'].copy(), 1, 0)\n",
    "    \n",
    "    return df, targets, stats, opp_stats, meta\n",
    "\n",
    "data, targets, stats, opp_stats, meta = feature_eng(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4dc2d871",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "teams = set(data['team_name'].unique()).union(set(data['opp_name'].unique()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6ce487fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['season', 'team_score', 'opp_score', 'is_home', 'numot', 'team_fgm', 'team_fga', 'team_fgm3', 'team_fga3', 'team_ftm', 'team_fta', 'team_or', 'team_dr', 'team_ast', 'team_to', 'team_stl', 'team_blk', 'team_pf', 'opp_fgm', 'opp_fga', 'opp_fgm3', 'opp_fga3', 'opp_ftm', 'opp_fta', 'opp_or', 'opp_dr', 'opp_ast', 'opp_to', 'opp_stl', 'opp_blk', 'opp_pf', 'team_name', 'opp_name', 'date', 'match_id', 'score_diff_pct', 'oreb_pct', 'dreb_pct', 'total_reb_pct', 'fgm3_diff_pct', 'ftm_diff_pct', 'score_total', 'blk_pct_diff', 'ast_pct_diff', 'to_pct_diff', 'agg_pct_diff', 'opp_score_diff_pct', 'opp_dreb_pct', 'opp_oreb_pct', 'opp_total_reb_pct', 'opp_fgm3_diff_pct', 'opp_ftm_diff_pct', 'opp_score_total', 'opp_blk_pct_diff', 'opp_ast_pct_diff', 'opp_to_pct_diff', 'opp_agg_pct_diff', 'days_rest', 'opp_days_rest', 'result']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>season</th>\n",
       "      <th>team_score</th>\n",
       "      <th>opp_score</th>\n",
       "      <th>is_home</th>\n",
       "      <th>numot</th>\n",
       "      <th>team_fgm</th>\n",
       "      <th>team_fga</th>\n",
       "      <th>team_fgm3</th>\n",
       "      <th>team_fga3</th>\n",
       "      <th>team_ftm</th>\n",
       "      <th>...</th>\n",
       "      <th>opp_fgm3_diff_pct</th>\n",
       "      <th>opp_ftm_diff_pct</th>\n",
       "      <th>opp_score_total</th>\n",
       "      <th>opp_blk_pct_diff</th>\n",
       "      <th>opp_ast_pct_diff</th>\n",
       "      <th>opp_to_pct_diff</th>\n",
       "      <th>opp_agg_pct_diff</th>\n",
       "      <th>days_rest</th>\n",
       "      <th>opp_days_rest</th>\n",
       "      <th>result</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2003</td>\n",
       "      <td>63</td>\n",
       "      <td>70</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>67</td>\n",
       "      <td>6</td>\n",
       "      <td>24</td>\n",
       "      <td>9</td>\n",
       "      <td>...</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.052632</td>\n",
       "      <td>-0.501887</td>\n",
       "      <td>-0.200000</td>\n",
       "      <td>0.391304</td>\n",
       "      <td>0.040000</td>\n",
       "      <td>-0.043478</td>\n",
       "      <td>0.115068</td>\n",
       "      <td>0.115068</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2003</td>\n",
       "      <td>62</td>\n",
       "      <td>68</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>53</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>16</td>\n",
       "      <td>...</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>-0.185185</td>\n",
       "      <td>-0.490566</td>\n",
       "      <td>-0.333333</td>\n",
       "      <td>0.238095</td>\n",
       "      <td>0.121951</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.115068</td>\n",
       "      <td>0.115068</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2003</td>\n",
       "      <td>61</td>\n",
       "      <td>73</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>73</td>\n",
       "      <td>3</td>\n",
       "      <td>26</td>\n",
       "      <td>14</td>\n",
       "      <td>...</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.096774</td>\n",
       "      <td>-0.505660</td>\n",
       "      <td>-0.428571</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>-0.090909</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.115068</td>\n",
       "      <td>0.115068</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2003</td>\n",
       "      <td>50</td>\n",
       "      <td>56</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>49</td>\n",
       "      <td>6</td>\n",
       "      <td>22</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.333333</td>\n",
       "      <td>0.360000</td>\n",
       "      <td>-0.400000</td>\n",
       "      <td>-0.200000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>-0.225806</td>\n",
       "      <td>0.084746</td>\n",
       "      <td>0.115068</td>\n",
       "      <td>0.115068</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2003</td>\n",
       "      <td>77</td>\n",
       "      <td>71</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>61</td>\n",
       "      <td>6</td>\n",
       "      <td>14</td>\n",
       "      <td>11</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.214286</td>\n",
       "      <td>-0.558491</td>\n",
       "      <td>-0.600000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.166667</td>\n",
       "      <td>-0.066667</td>\n",
       "      <td>0.115068</td>\n",
       "      <td>0.115068</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 60 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   season  team_score  opp_score  is_home  numot  team_fgm  team_fga  \\\n",
       "0    2003          63         70        0      0        24        67   \n",
       "1    2003          62         68        0      0        22        53   \n",
       "2    2003          61         73        0      0        22        73   \n",
       "3    2003          50         56        0      0        18        49   \n",
       "4    2003          77         71        0      0        30        61   \n",
       "\n",
       "   team_fgm3  team_fga3  team_ftm  ...  opp_fgm3_diff_pct  opp_ftm_diff_pct  \\\n",
       "0          6         24         9  ...           0.142857          0.052632   \n",
       "1          2         10        16  ...           0.200000         -0.185185   \n",
       "2          3         26        14  ...           0.454545          0.096774   \n",
       "3          6         22         8  ...          -0.333333          0.360000   \n",
       "4          6         14        11  ...           0.000000          0.214286   \n",
       "\n",
       "   opp_score_total  opp_blk_pct_diff  opp_ast_pct_diff  opp_to_pct_diff  \\\n",
       "0        -0.501887         -0.200000          0.391304         0.040000   \n",
       "1        -0.490566         -0.333333          0.238095         0.121951   \n",
       "2        -0.505660         -0.428571          0.250000        -0.090909   \n",
       "3        -0.400000         -0.200000          0.100000        -0.225806   \n",
       "4        -0.558491         -0.600000          0.000000        -0.166667   \n",
       "\n",
       "   opp_agg_pct_diff  days_rest  opp_days_rest  result  \n",
       "0         -0.043478   0.115068       0.115068       0  \n",
       "1          0.000000   0.115068       0.115068       0  \n",
       "2          0.090909   0.115068       0.115068       0  \n",
       "3          0.084746   0.115068       0.115068       0  \n",
       "4         -0.066667   0.115068       0.115068       1  \n",
       "\n",
       "[5 rows x 60 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "print(list(data))\n",
    "data.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f97a25f0",
   "metadata": {},
   "source": [
    "### Run Classic Elo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2cca8a00",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████| 103280/103280 [00:02<00:00, 42719.22it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>p1_id</th>\n",
       "      <th>p1_name</th>\n",
       "      <th>p2_id</th>\n",
       "      <th>p2_name</th>\n",
       "      <th>p1_rating</th>\n",
       "      <th>p2_rating</th>\n",
       "      <th>prediction</th>\n",
       "      <th>result</th>\n",
       "      <th>ratings_delta</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>212</td>\n",
       "      <td>Syracuse</td>\n",
       "      <td>132</td>\n",
       "      <td>Memphis</td>\n",
       "      <td>1500.000000</td>\n",
       "      <td>1500.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0</td>\n",
       "      <td>-20.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>73</td>\n",
       "      <td>Oklahoma</td>\n",
       "      <td>281</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>1500.000000</td>\n",
       "      <td>1500.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0</td>\n",
       "      <td>-20.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>118</td>\n",
       "      <td>Villanova</td>\n",
       "      <td>221</td>\n",
       "      <td>Marquette</td>\n",
       "      <td>1500.000000</td>\n",
       "      <td>1500.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0</td>\n",
       "      <td>-20.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>346</td>\n",
       "      <td>Winthrop</td>\n",
       "      <td>359</td>\n",
       "      <td>N Illinois</td>\n",
       "      <td>1500.000000</td>\n",
       "      <td>1500.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0</td>\n",
       "      <td>-20.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>133</td>\n",
       "      <td>Texas</td>\n",
       "      <td>251</td>\n",
       "      <td>Georgia</td>\n",
       "      <td>1500.000000</td>\n",
       "      <td>1500.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1</td>\n",
       "      <td>20.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103275</th>\n",
       "      <td>328</td>\n",
       "      <td>St Peter's</td>\n",
       "      <td>30</td>\n",
       "      <td>North Carolina</td>\n",
       "      <td>1620.746851</td>\n",
       "      <td>2047.468070</td>\n",
       "      <td>0.078971</td>\n",
       "      <td>0</td>\n",
       "      <td>-3.158858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103276</th>\n",
       "      <td>6</td>\n",
       "      <td>Kansas</td>\n",
       "      <td>95</td>\n",
       "      <td>Miami FL</td>\n",
       "      <td>2155.153018</td>\n",
       "      <td>1959.018606</td>\n",
       "      <td>0.755662</td>\n",
       "      <td>1</td>\n",
       "      <td>9.773529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103277</th>\n",
       "      <td>6</td>\n",
       "      <td>Kansas</td>\n",
       "      <td>118</td>\n",
       "      <td>Villanova</td>\n",
       "      <td>2164.926547</td>\n",
       "      <td>2157.342296</td>\n",
       "      <td>0.510913</td>\n",
       "      <td>1</td>\n",
       "      <td>19.563485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103278</th>\n",
       "      <td>30</td>\n",
       "      <td>North Carolina</td>\n",
       "      <td>353</td>\n",
       "      <td>Duke</td>\n",
       "      <td>2050.626928</td>\n",
       "      <td>2096.882959</td>\n",
       "      <td>0.433823</td>\n",
       "      <td>1</td>\n",
       "      <td>22.647090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103279</th>\n",
       "      <td>6</td>\n",
       "      <td>Kansas</td>\n",
       "      <td>30</td>\n",
       "      <td>North Carolina</td>\n",
       "      <td>2184.490031</td>\n",
       "      <td>2073.274018</td>\n",
       "      <td>0.654801</td>\n",
       "      <td>1</td>\n",
       "      <td>13.807955</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>103280 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        p1_id         p1_name  p2_id         p2_name    p1_rating  \\\n",
       "0         212        Syracuse    132         Memphis  1500.000000   \n",
       "1          73        Oklahoma    281         Alabama  1500.000000   \n",
       "2         118       Villanova    221       Marquette  1500.000000   \n",
       "3         346        Winthrop    359      N Illinois  1500.000000   \n",
       "4         133           Texas    251         Georgia  1500.000000   \n",
       "...       ...             ...    ...             ...          ...   \n",
       "103275    328      St Peter's     30  North Carolina  1620.746851   \n",
       "103276      6          Kansas     95        Miami FL  2155.153018   \n",
       "103277      6          Kansas    118       Villanova  2164.926547   \n",
       "103278     30  North Carolina    353            Duke  2050.626928   \n",
       "103279      6          Kansas     30  North Carolina  2184.490031   \n",
       "\n",
       "          p2_rating  prediction  result  ratings_delta  \n",
       "0       1500.000000    0.500000       0     -20.000000  \n",
       "1       1500.000000    0.500000       0     -20.000000  \n",
       "2       1500.000000    0.500000       0     -20.000000  \n",
       "3       1500.000000    0.500000       0     -20.000000  \n",
       "4       1500.000000    0.500000       1      20.000000  \n",
       "...             ...         ...     ...            ...  \n",
       "103275  2047.468070    0.078971       0      -3.158858  \n",
       "103276  1959.018606    0.755662       1       9.773529  \n",
       "103277  2157.342296    0.510913       1      19.563485  \n",
       "103278  2096.882959    0.433823       1      22.647090  \n",
       "103279  2073.274018    0.654801       1      13.807955  \n",
       "\n",
       "[103280 rows x 9 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "class StatefulSystem:\n",
    "    def __init__(self):\n",
    "        self.history = []  # to store history of predictions and results\n",
    "\n",
    "    def predict_1v1(self, player1, player2, **kwargs):\n",
    "        raise NotImplementedError  # This method should be implemented in child classes\n",
    "\n",
    "    def update_1v1(self, player1, player2, result, **kwargs):\n",
    "        raise NotImplementedError  # This method should be implemented in child classes\n",
    "        \n",
    "class PlayerNode():\n",
    "    def __init__(self, rating):\n",
    "        self.rating=rating\n",
    "        \n",
    "class EloNode(PlayerNode):\n",
    "    def __init__(self,_id, name, rating=1500):\n",
    "        super().__init__(rating)\n",
    "        self._id = _id\n",
    "        self.name = name\n",
    "        self.rating = rating\n",
    "        self.rank = 200\n",
    "        \n",
    "class EloSystem(StatefulSystem):\n",
    "    def __init__(self, k_factor, meta_functions=None):\n",
    "        super().__init__()\n",
    "        self.history = []\n",
    "        self.k_factor = k_factor\n",
    "        ## for edge info like home, days off\n",
    "        self.meta_functions = meta_functions\n",
    "\n",
    "    def predict_1v1(self, player1, player2, **kwargs):\n",
    "        # Meta information can be accessed as dictionary items, e.g., kwargs['is_home'], kwargs['days_off']\n",
    "        rd = player1.rating - player2.rating\n",
    "        if self.meta_functions is not None:\n",
    "            ## add all adjustments for meta information\n",
    "            for meta_key, meta_function in self.meta_functions.items():\n",
    "                rd += meta_function(kwargs[meta_key])\n",
    "        prediction = 1/(1+10**(-rd/400))\n",
    "        return prediction\n",
    "    def update_1v1(self, prediction, result):\n",
    "        points_exchanged = self.k_factor*(result-prediction)\n",
    "        return points_exchanged\n",
    "    \n",
    "    def play_match(self, p1, p2, result, update_both=False, **kwargs):\n",
    "        prediction = self.predict_1v1(p1, p2, **kwargs)\n",
    "        ratings_delta = self.update_1v1(prediction, result)\n",
    "        self.history.append([p1._id, p1.name, p2._id, p2.name, p1.rating, p2.rating, prediction, result, ratings_delta])\n",
    "        p1.rating+=ratings_delta\n",
    "        if update_both:\n",
    "            p2.rating-=ratings_delta\n",
    "        return p1, p2\n",
    "    \n",
    "    def get_history(self):\n",
    "        return pd.DataFrame(self.history, columns=['p1_id','p1_name','p2_id','p2_name','p1_rating','p2_rating','prediction','result','ratings_delta'])\n",
    "\n",
    "elo_sys = EloSystem(k_factor=40)\n",
    "# player_ratings = {_id:EloNode(_id, name, 1500) for _id, name in player_names.items()}\n",
    "team_ratings = {name:EloNode(i, name, 1500) for i, name in enumerate(teams)}\n",
    "for index, row in tqdm(data.iterrows(), total=len(data)):\n",
    "    \n",
    "    t1 = row['team_name']\n",
    "    t2 = row['opp_name']\n",
    "    \n",
    "    t1_node = team_ratings[t1]\n",
    "    t2_node = team_ratings[t2]\n",
    "    \n",
    "    result = 1 if (row['team_score']-row['opp_score'])>0 else 0\n",
    "\n",
    "    t1_node, t2_node = elo_sys.play_match(t1_node, t2_node, result, update_both=True)\n",
    "    \n",
    "    team_ratings[t1] = t1_node\n",
    "    team_ratings[t2] = t2_node\n",
    "    \n",
    "    \n",
    "hist = elo_sys.get_history()\n",
    "hist\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fb0ae86a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5686497097006444"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import log_loss\n",
    "## 20: 0.5717748620218386\n",
    "## 30: 0.5688727434688168\n",
    "## 40: 0.5684751964171788\n",
    "## 45: 0.5694965390004977\n",
    "## 60: 0.5735\n",
    "grade_cutoff = int(0.2*len(hist))\n",
    "log_loss(hist[-grade_cutoff:]['result'].values, hist[-grade_cutoff:]['prediction'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f58b6d31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Kansas</td>\n",
       "      <td>Kansas</td>\n",
       "      <td>2198.297987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>262</th>\n",
       "      <td>Gonzaga</td>\n",
       "      <td>Gonzaga</td>\n",
       "      <td>2182.581492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>Villanova</td>\n",
       "      <td>Villanova</td>\n",
       "      <td>2137.778811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186</th>\n",
       "      <td>Baylor</td>\n",
       "      <td>Baylor</td>\n",
       "      <td>2127.109214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>216</th>\n",
       "      <td>Houston</td>\n",
       "      <td>Houston</td>\n",
       "      <td>2082.292836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>353</th>\n",
       "      <td>Duke</td>\n",
       "      <td>Duke</td>\n",
       "      <td>2074.235869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>Arizona</td>\n",
       "      <td>Arizona</td>\n",
       "      <td>2061.981370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>North Carolina</td>\n",
       "      <td>North Carolina</td>\n",
       "      <td>2059.466062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>270</th>\n",
       "      <td>Tennessee</td>\n",
       "      <td>Tennessee</td>\n",
       "      <td>2042.358774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>274</th>\n",
       "      <td>Arkansas</td>\n",
       "      <td>Arkansas</td>\n",
       "      <td>2038.398964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>Purdue</td>\n",
       "      <td>Purdue</td>\n",
       "      <td>2026.140615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248</th>\n",
       "      <td>Providence</td>\n",
       "      <td>Providence</td>\n",
       "      <td>2019.319640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250</th>\n",
       "      <td>Texas Tech</td>\n",
       "      <td>Texas Tech</td>\n",
       "      <td>2014.224951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>Illinois</td>\n",
       "      <td>Illinois</td>\n",
       "      <td>2011.074128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>228</th>\n",
       "      <td>Iowa</td>\n",
       "      <td>Iowa</td>\n",
       "      <td>2009.492244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>351</th>\n",
       "      <td>UCLA</td>\n",
       "      <td>UCLA</td>\n",
       "      <td>2002.517578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239</th>\n",
       "      <td>Wisconsin</td>\n",
       "      <td>Wisconsin</td>\n",
       "      <td>1991.650311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>Creighton</td>\n",
       "      <td>Creighton</td>\n",
       "      <td>1988.700399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>Michigan</td>\n",
       "      <td>Michigan</td>\n",
       "      <td>1970.611649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>Auburn</td>\n",
       "      <td>Auburn</td>\n",
       "      <td>1969.576122</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id            name       rating\n",
       "6            Kansas          Kansas  2198.297987\n",
       "262         Gonzaga         Gonzaga  2182.581492\n",
       "118       Villanova       Villanova  2137.778811\n",
       "186          Baylor          Baylor  2127.109214\n",
       "216         Houston         Houston  2082.292836\n",
       "353            Duke            Duke  2074.235869\n",
       "171         Arizona         Arizona  2061.981370\n",
       "30   North Carolina  North Carolina  2059.466062\n",
       "270       Tennessee       Tennessee  2042.358774\n",
       "274        Arkansas        Arkansas  2038.398964\n",
       "235          Purdue          Purdue  2026.140615\n",
       "248      Providence      Providence  2019.319640\n",
       "250      Texas Tech      Texas Tech  2014.224951\n",
       "56         Illinois        Illinois  2011.074128\n",
       "228            Iowa            Iowa  2009.492244\n",
       "351            UCLA            UCLA  2002.517578\n",
       "239       Wisconsin       Wisconsin  1991.650311\n",
       "130       Creighton       Creighton  1988.700399\n",
       "105        Michigan        Michigan  1970.611649\n",
       "165          Auburn          Auburn  1969.576122"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "rtg_df = pd.DataFrame([[k,v.name, v.rating] for k,v in team_ratings.items()], columns=['id','name','rating'])\n",
    "rtg_df.sort_values(by='rating', ascending=False).head(20)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eddaff44",
   "metadata": {},
   "source": [
    "### Create Pytorch Elo Classes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "558edd06",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# One neuron to learn scaling and a sigmoid activation function.\n",
    "class EloPredictNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(1, 1, bias=False)  # No bias so that ratings delta of 0 = 50% win prob\n",
    "\n",
    "    def forward(self, rd):\n",
    "        return torch.sigmoid(self.linear(rd))\n",
    "    \n",
    "class EloUpdateNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(1, 1, bias=False)  # No bias so that matches are symmetrical (no advantage to being player A)\n",
    "        \n",
    "    def forward(self, pred_error):\n",
    "        return self.linear(pred_error)\n",
    "    \n",
    "class NetworkNode(PlayerNode):\n",
    "    def __init__(self,_id, name, rating=0):\n",
    "        super().__init__(rating)\n",
    "        self._id = _id\n",
    "        self.name = name\n",
    "        self.rating = rating\n",
    "        self.last_rating = rating\n",
    "        self.last_error = 0.5\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93ec252c",
   "metadata": {},
   "source": [
    "### Let's try learning the weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "75a4a9ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## split into train/test\n",
    "percent_30 = int(0.3*len(data))\n",
    "train = data.copy()[:-percent_30]\n",
    "test = data.copy()[-percent_30:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "48da4a22",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "predict_model = EloPredictNN()\n",
    "predict_optimizer = Adam(predict_model.parameters(), lr=1e-6)\n",
    "\n",
    "update_model = EloUpdateNN()\n",
    "update_optimizer = Adam(update_model.parameters(), lr=1e-6)\n",
    "\n",
    "batch_size = 24 \n",
    "num_batches = len(train)//batch_size\n",
    "num_epochs = 2\n",
    "best_val_loss = np.inf\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5ffc2a02",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 3011/3011 [00:03<00:00, 879.59it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████| 103280/103280 [00:07<00:00, 13308.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NN validation log loss (hopefully < 0.69 and >0.55): 18.186456775669807\n",
      "Saving parameters...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 3011/3011 [00:03<00:00, 912.68it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████| 103280/103280 [00:07<00:00, 13178.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NN validation log loss (hopefully < 0.69 and >0.55): 18.174469648354506\n",
      "Saving parameters...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "## temporal component important so no shuffle\n",
    "for j in range(num_epochs):\n",
    "    network_team_ratings = {name:NetworkNode(i, name, 0) for i, name in enumerate(teams)}\n",
    "    epoch_loss = []\n",
    "    predict_model.train()\n",
    "    update_model.train()\n",
    "    for i in tqdm(range(num_batches-1), total=num_batches-1):\n",
    "        predict_optimizer.zero_grad()\n",
    "        update_optimizer.zero_grad()\n",
    "        train_data = train[i*batch_size:(i+1)*batch_size].copy()\n",
    "\n",
    "        results = torch.from_numpy(train_data.result.copy().astype('float32').values).view(-1,1)\n",
    "        \n",
    "        t1_nodes = [network_team_ratings[k] for k in train_data.team_name.values]\n",
    "        t2_nodes = [network_team_ratings[k] for k in train_data.opp_name.values]\n",
    "        \n",
    "        predict_X = torch.Tensor([t2_nodes[k].rating-t1_nodes[k].rating for k in range(len(t1_nodes))]).view(-1,1)\n",
    "        \n",
    "        ## I found that only updating one model at a time seems to give more stable results\n",
    "        ## worth investigating further\n",
    "        update_or_predict = np.random.random()\n",
    "        \n",
    "        if update_or_predict>0.5:\n",
    "            ## PREDICT MODEL (easy part)\n",
    "            ## have to make it symmetrical (p2_rating-p1_rating and p1_rating-p2_rating)\n",
    "            predictions = predict_model(predict_X)\n",
    "            \n",
    "            predict_loss = nn.BCELoss()(predictions, results)\n",
    "            predict_loss.backward()\n",
    "\n",
    "            # Update the model's parameters\n",
    "            ## for the first few iterations, let ratings stabilize\n",
    "            if (j>0)&(i < 20):\n",
    "                continue\n",
    "            elif (j>1)&(i < 100):\n",
    "                continue\n",
    "            else:\n",
    "                predict_optimizer.step()\n",
    "            # Zero the gradients since PyTorch accumulates them\n",
    "            predict_optimizer.zero_grad()\n",
    "        \n",
    "        else:\n",
    "            ## UPDATE MODEL (slightly harder)\n",
    "            ## use previous game's results to calculate loss of the update model\n",
    "            predictions = predict_model(predict_X)\n",
    "            predict_optimizer.zero_grad()\n",
    "            \n",
    "            ## directionality is important here, last error is simply result - prediction (is negative if the player loses)\n",
    "            t1_update_X = torch.Tensor([t1_node.last_error for t1_node in t1_nodes]).view(-1,1)\n",
    "            t2_update_X = torch.Tensor([t2_node.last_error for t2_node in t2_nodes]).view(-1,1)\n",
    "\n",
    "            t1_update_predictions = update_model(t1_update_X)\n",
    "            t2_update_predictions = update_model(t2_update_X)\n",
    "\n",
    "            ## want both baseline predict model (no update) and predict model with updates. Compare to create loss\n",
    "            baseline_X = torch.Tensor([t2_nodes[k].last_rating-t1_nodes[k].last_rating for k in range(len(t1_nodes))]).view(-1,1)\n",
    "            update_model_X = torch.Tensor([t2_nodes[k].last_rating+t2_update_predictions[k] - t1_nodes[k].last_rating+t1_update_predictions[k] for k in range(len(t1_nodes))]).view(-1,1)\n",
    "\n",
    "            baseline_predictions = predict_model(baseline_X)\n",
    "            update_model_predictions = predict_model(update_model_X)\n",
    "            baseline_BCE = nn.BCELoss()(baseline_predictions, results)\n",
    "            update_model_BCE = nn.BCELoss()(update_model_predictions, results)\n",
    "            ## lower is better, has to be negative if improving ratings\n",
    "            update_loss = update_model_BCE-baseline_BCE\n",
    "            update_loss.backward()\n",
    "            ## skip the first few iterations of the later epochs to give some time for ratings to develop\n",
    "            if (j>0)&(i < 25):\n",
    "                continue\n",
    "            elif (j>1)&(i < 100):\n",
    "                continue\n",
    "            else:\n",
    "                update_optimizer.step()\n",
    "            update_optimizer.zero_grad()\n",
    "        \n",
    "        ## now just update the nodes with the predictions\n",
    "        ## in Elo this step is k*(result-predictions)\n",
    "        ## we are finding k\n",
    "        pred_error = results - predictions\n",
    "        epoch_loss.extend(list(pred_error[:,0].detach().numpy()))\n",
    "        updates = update_model(pred_error)\n",
    "        new_ratings = [t1_nodes[k].rating+updates[k] for k in range(len(t1_nodes))]\n",
    "\n",
    "        for l, team_node in enumerate(t1_nodes):\n",
    "            team_node.last_rating = copy(team_node.rating)\n",
    "            team_node.last_error = pred_error[l, 0]\n",
    "            team_node.rating = float(new_ratings[l])\n",
    "            network_team_ratings[team_node._id] = copy(team_node)\n",
    "            \n",
    "    ## calculate val\n",
    "    predict_model.eval()\n",
    "    update_model.eval()\n",
    "    \n",
    "    network_team_ratings = {name:NetworkNode(_id, name, 0) for _id, name in enumerate(teams)}\n",
    "\n",
    "    nn_history = []\n",
    "    for index, row in tqdm(data.iterrows(), total=len(data)):\n",
    "        \n",
    "        t1_id, t2_id = row['team_name'], row['opp_name']\n",
    "        \n",
    "        t1_nn_node = network_team_ratings[t1_id]\n",
    "        t2_nn_node = network_team_ratings[t2_id]\n",
    "        result = row['result']\n",
    "\n",
    "        rtg_diff = t2_nn_node.rating-t1_nn_node.rating\n",
    "        nn_prediction = predict_model(torch.Tensor([[rtg_diff]]))\n",
    "        error = result - nn_prediction\n",
    "        rtg_update = update_model(torch.Tensor([[error]]))\n",
    "        nn_history.append([t1_nn_node._id, t1_nn_node.name, t2_nn_node._id, t2_nn_node.name, float(t1_nn_node.rating), float(t2_nn_node.rating), float(nn_prediction), result, float(rtg_update)])\n",
    "        t1_nn_node.rating =  t1_nn_node.rating + rtg_update\n",
    "        t2_nn_node.rating =  t2_nn_node.rating - rtg_update\n",
    "        \n",
    "        network_team_ratings[t1_id] = t1_nn_node\n",
    "        network_team_ratings[t2_id] = t2_nn_node\n",
    "\n",
    "    nn_hist = pd.DataFrame(nn_history, columns=['t1_id','t1_name','t2_id','t2_name','t1_rating','t2_rating','prediction','result','ratings_delta'])\n",
    "    val_loss = log_loss(nn_hist[-grade_cutoff:]['result'].values, nn_hist[-grade_cutoff:]['prediction'].values)\n",
    "    print(f\"NN validation log loss (hopefully < 0.69 and >0.55): {val_loss}\")\n",
    "    \n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        print(\"Saving parameters...\")\n",
    "        torch.save(predict_model.state_dict(), 'elo_predict_nn_best_model.pth')\n",
    "        torch.save(update_model.state_dict(), 'elo_update_nn_best_model.pth')\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2684330c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_model = EloPredictNN()\n",
    "predict_model.load_state_dict(torch.load('elo_predict_nn_best_model.pth'))\n",
    "update_model = EloUpdateNN()\n",
    "update_model.load_state_dict(torch.load('elo_update_nn_best_model.pth'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "199f7cfa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>Chicago St</td>\n",
       "      <td>Chicago St</td>\n",
       "      <td>396.918915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>San Jose St</td>\n",
       "      <td>San Jose St</td>\n",
       "      <td>388.031921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>MD E Shore</td>\n",
       "      <td>MD E Shore</td>\n",
       "      <td>379.620850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>Ark Pine Bluff</td>\n",
       "      <td>Ark Pine Bluff</td>\n",
       "      <td>374.206635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>278</th>\n",
       "      <td>Fordham</td>\n",
       "      <td>Fordham</td>\n",
       "      <td>347.904633</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id            name      rating\n",
       "163      Chicago St      Chicago St  396.918915\n",
       "74      San Jose St     San Jose St  388.031921\n",
       "31       MD E Shore      MD E Shore  379.620850\n",
       "296  Ark Pine Bluff  Ark Pine Bluff  374.206635\n",
       "278         Fordham         Fordham  347.904633"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rtg_df = pd.DataFrame([[k,v.name, float(v.rating)] for k,v in network_team_ratings.items()], columns=['id','name','rating'])\n",
    "rtg_df.sort_values(by='rating', ascending=False).head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4ee971e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EloUpdateNN(\n",
       "  (linear): Linear(in_features=1, out_features=1, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "predict_model.eval()\n",
    "update_model.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cc1fb7af",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████| 103280/103280 [00:08<00:00, 12123.54it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "elo_sys = EloSystem(k_factor=50)\n",
    "\n",
    "player_ratings = {name:EloNode(_id, name, 1500) for _id, name in enumerate(teams)}\n",
    "network_player_ratings = {name:NetworkNode(_id, name, 0) for _id, name in enumerate(teams)}\n",
    "\n",
    "nn_history = []\n",
    "data = data.sort_values(by=['date','team_name']).reset_index(drop=True)\n",
    "for index, row in tqdm(data.iterrows(), total=len(data)):\n",
    "    ## randomize who is p1 and who is p2\n",
    "    p1_id, p2_id = row['team_name'], row['opp_name']\n",
    "    p1_node = player_ratings[p1_id]\n",
    "    p2_node = player_ratings[p2_id]\n",
    "    result = row['result']\n",
    "    p1_node, p2_node = elo_sys.play_match(p1_node, p2_node, result)\n",
    "    \n",
    "    p1_nn_node = network_player_ratings[p1_id]\n",
    "    p2_nn_node = network_player_ratings[p2_id]\n",
    "    \n",
    "    rtg_diff = p2_nn_node.rating-p1_nn_node.rating\n",
    "    nn_prediction = predict_model(torch.Tensor([[rtg_diff]]))\n",
    "    error = result - nn_prediction\n",
    "    rtg_update = update_model(torch.Tensor([[error]]))\n",
    "    nn_history.append([row['date'], row['match_id'], p1_nn_node._id, p1_nn_node.name, p2_nn_node._id, p2_nn_node.name, float(p1_nn_node.rating), float(p2_nn_node.rating), float(nn_prediction), result, float(rtg_update)])\n",
    "    p1_nn_node.rating += rtg_update\n",
    "    p2_nn_node.rating -= rtg_update\n",
    "    \n",
    "    player_ratings[p1_id] = p1_node\n",
    "    player_ratings[p2_id] = p2_node\n",
    "    \n",
    "    \n",
    "hist = elo_sys.get_history()\n",
    "nn_hist = pd.DataFrame(nn_history, columns=['date','match_id','p1_id','p1_name','p2_id','p2_name','p1_rating','p2_rating','prediction','result','ratings_delta'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1cd41c35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "103280 103280\n",
      "reg log loss:  0.5863064816065223\n",
      "nn log loss:  18.172468894528727\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "grade_cutoff = int(0.2*len(hist))\n",
    "print(len(hist),len(nn_hist))\n",
    "reg_log_loss = log_loss(hist[-grade_cutoff:]['result'].values, hist[-grade_cutoff:]['prediction'].values)\n",
    "nn_log_loss = log_loss(nn_hist[-grade_cutoff:]['result'].values, nn_hist[-grade_cutoff:]['prediction'].values)\n",
    "print(\"reg log loss: \", reg_log_loss)\n",
    "print(\"nn log loss: \", nn_log_loss)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fe5bb3a",
   "metadata": {},
   "source": [
    "\n",
    "### More Advanced Model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3e5d8a1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16\n"
     ]
    }
   ],
   "source": [
    "\n",
    "vec_size = 3\n",
    "\n",
    "class PairwisePredictNN(nn.Module):\n",
    "    \"\"\"\n",
    "    takes [\n",
    "    player 2 vec - player 1 vec (distance), \n",
    "    meta\n",
    "    ] and predicts match outcome\n",
    "    \"\"\"\n",
    "    def __init__(self, input_size, hidden_dim, output_size):\n",
    "        super().__init__()\n",
    "        self.input_size=input_size\n",
    "        self.hidden_dim=hidden_dim\n",
    "        self.output_size=output_size\n",
    "        self.linear = nn.Linear(input_size, self.hidden_dim)\n",
    "        self.linear2 = nn.Linear(self.hidden_dim, self.output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.linear(x))\n",
    "        x = self.linear2(x)\n",
    "        ## ensure total is non negative\n",
    "#         x[:, 2] = torch.nn.functional.softplus(x[:, 2])\n",
    "        return x\n",
    "    \n",
    "class PairwiseUpdateNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_dim, player_vec_size):\n",
    "        super().__init__()\n",
    "        \"\"\"\n",
    "        takes [\n",
    "        player 2 vec - player 1 vec (distance), \n",
    "        meta,\n",
    "        stat_results\n",
    "        ] and updates player vecs symmetrically\n",
    "        \"\"\"\n",
    "        self.input_size=input_size\n",
    "        self.hidden_dim=hidden_dim\n",
    "        self.player_vec_size=player_vec_size\n",
    "        self.linear = nn.Linear(self.input_size, self.hidden_dim) \n",
    "        self.linear2 = nn.Linear(self.hidden_dim, self.player_vec_size)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.linear(x))\n",
    "        x = self.linear2(x)\n",
    "        return torch.tanh(x) *0.5\n",
    "    \n",
    "class NetworkNode(PlayerNode):\n",
    "    def __init__(self,_id, name, rating=torch.zeros(vec_size)):\n",
    "        super().__init__(rating)\n",
    "        self._id = _id\n",
    "        self.name = name\n",
    "        self.rating = rating\n",
    "        self.last_rating = rating\n",
    "        ### vector created at end of last match (used to train update model)\n",
    "        ### distance, meta, \n",
    "        self.last_vector = torch.cat([torch.zeros(vec_size), torch.zeros(len(meta)), torch.zeros(len(stats))])\n",
    "        \n",
    "    def get_last_update_input(self):\n",
    "        return self.last_vector\n",
    "    \n",
    "    def pregame_state(self):\n",
    "        pregame_state = [self._id, self.name]\n",
    "        pregame_state.extend(list(self.last_rating.detach().numpy()))\n",
    "        return pregame_state\n",
    "        \n",
    "\n",
    "\n",
    "print(vec_size+len(meta)+len(stats))\n",
    "test = NetworkNode(100, \"Blake\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "57670ee6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>season</th>\n",
       "      <th>team_score</th>\n",
       "      <th>opp_score</th>\n",
       "      <th>is_home</th>\n",
       "      <th>numot</th>\n",
       "      <th>team_fgm</th>\n",
       "      <th>team_fga</th>\n",
       "      <th>team_fgm3</th>\n",
       "      <th>team_fga3</th>\n",
       "      <th>team_ftm</th>\n",
       "      <th>...</th>\n",
       "      <th>opp_fgm3_diff_pct</th>\n",
       "      <th>opp_ftm_diff_pct</th>\n",
       "      <th>opp_score_total</th>\n",
       "      <th>opp_blk_pct_diff</th>\n",
       "      <th>opp_ast_pct_diff</th>\n",
       "      <th>opp_to_pct_diff</th>\n",
       "      <th>opp_agg_pct_diff</th>\n",
       "      <th>days_rest</th>\n",
       "      <th>opp_days_rest</th>\n",
       "      <th>result</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2003</td>\n",
       "      <td>62</td>\n",
       "      <td>68</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>53</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>16</td>\n",
       "      <td>...</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>-0.185185</td>\n",
       "      <td>-0.490566</td>\n",
       "      <td>-0.333333</td>\n",
       "      <td>0.238095</td>\n",
       "      <td>0.121951</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.115068</td>\n",
       "      <td>0.115068</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2003</td>\n",
       "      <td>63</td>\n",
       "      <td>70</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>67</td>\n",
       "      <td>6</td>\n",
       "      <td>24</td>\n",
       "      <td>9</td>\n",
       "      <td>...</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.052632</td>\n",
       "      <td>-0.501887</td>\n",
       "      <td>-0.200000</td>\n",
       "      <td>0.391304</td>\n",
       "      <td>0.040000</td>\n",
       "      <td>-0.043478</td>\n",
       "      <td>0.115068</td>\n",
       "      <td>0.115068</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2003</td>\n",
       "      <td>77</td>\n",
       "      <td>71</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>61</td>\n",
       "      <td>6</td>\n",
       "      <td>14</td>\n",
       "      <td>11</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.214286</td>\n",
       "      <td>-0.558491</td>\n",
       "      <td>-0.600000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.166667</td>\n",
       "      <td>-0.066667</td>\n",
       "      <td>0.115068</td>\n",
       "      <td>0.115068</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2003</td>\n",
       "      <td>61</td>\n",
       "      <td>73</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>73</td>\n",
       "      <td>3</td>\n",
       "      <td>26</td>\n",
       "      <td>14</td>\n",
       "      <td>...</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.096774</td>\n",
       "      <td>-0.505660</td>\n",
       "      <td>-0.428571</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>-0.090909</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.115068</td>\n",
       "      <td>0.115068</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2003</td>\n",
       "      <td>50</td>\n",
       "      <td>56</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>49</td>\n",
       "      <td>6</td>\n",
       "      <td>22</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.333333</td>\n",
       "      <td>0.360000</td>\n",
       "      <td>-0.400000</td>\n",
       "      <td>-0.200000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>-0.225806</td>\n",
       "      <td>0.084746</td>\n",
       "      <td>0.115068</td>\n",
       "      <td>0.115068</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 60 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   season  team_score  opp_score  is_home  numot  team_fgm  team_fga  \\\n",
       "0    2003          62         68        0      0        22        53   \n",
       "1    2003          63         70        0      0        24        67   \n",
       "2    2003          77         71        0      0        30        61   \n",
       "3    2003          61         73        0      0        22        73   \n",
       "4    2003          50         56        0      0        18        49   \n",
       "\n",
       "   team_fgm3  team_fga3  team_ftm  ...  opp_fgm3_diff_pct  opp_ftm_diff_pct  \\\n",
       "0          2         10        16  ...           0.200000         -0.185185   \n",
       "1          6         24         9  ...           0.142857          0.052632   \n",
       "2          6         14        11  ...           0.000000          0.214286   \n",
       "3          3         26        14  ...           0.454545          0.096774   \n",
       "4          6         22         8  ...          -0.333333          0.360000   \n",
       "\n",
       "   opp_score_total  opp_blk_pct_diff  opp_ast_pct_diff  opp_to_pct_diff  \\\n",
       "0        -0.490566         -0.333333          0.238095         0.121951   \n",
       "1        -0.501887         -0.200000          0.391304         0.040000   \n",
       "2        -0.558491         -0.600000          0.000000        -0.166667   \n",
       "3        -0.505660         -0.428571          0.250000        -0.090909   \n",
       "4        -0.400000         -0.200000          0.100000        -0.225806   \n",
       "\n",
       "   opp_agg_pct_diff  days_rest  opp_days_rest  result  \n",
       "0          0.000000   0.115068       0.115068       0  \n",
       "1         -0.043478   0.115068       0.115068       0  \n",
       "2         -0.066667   0.115068       0.115068       1  \n",
       "3          0.090909   0.115068       0.115068       0  \n",
       "4          0.084746   0.115068       0.115068       0  \n",
       "\n",
       "[5 rows x 60 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "856f82f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "predict_model = PairwisePredictNN(\n",
    "    input_size=vec_size+len(meta),\n",
    "    hidden_dim=3,\n",
    "    output_size=3\n",
    ")\n",
    "predict_optimizer = Adam(predict_model.parameters(), lr=1e-4)\n",
    "\n",
    "update_model = PairwiseUpdateNN(\n",
    "    input_size = vec_size+len(meta)+len(stats),\n",
    "    hidden_dim = 9,\n",
    "    player_vec_size = 3\n",
    ")\n",
    "update_optimizer = Adam(update_model.parameters(), lr=1e-4)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "251a1a17",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train = data.copy()[:-percent_30]\n",
    "test = data.copy()[-percent_30:]\n",
    "batch_size = 32\n",
    "num_batches = len(train)//batch_size\n",
    "num_epochs = 7\n",
    "best_val_loss = np.inf\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "459974d9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "eb00355a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 2258/2258 [00:15<00:00, 146.27it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████| 103280/103280 [02:22<00:00, 723.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  prediction_reb  result_reb  prediction_total  result_total  \\\n",
      "prediction_reb          1.000000   -0.049878         -0.004652     -0.001618   \n",
      "result_reb             -0.049878    1.000000         -0.000980      0.002453   \n",
      "prediction_total       -0.004652   -0.000980          1.000000      0.047207   \n",
      "result_total           -0.001618    0.002453          0.047207      1.000000   \n",
      "prediction_score        0.909333   -0.058835         -0.031193     -0.002784   \n",
      "result_score           -0.066438    0.527572         -0.005283      0.004536   \n",
      "\n",
      "                  prediction_score  result_score  \n",
      "prediction_reb            0.909333     -0.066438  \n",
      "result_reb               -0.058835      0.527572  \n",
      "prediction_total         -0.031193     -0.005283  \n",
      "result_total             -0.002784      0.004536  \n",
      "prediction_score          1.000000     -0.076539  \n",
      "result_score             -0.076539      1.000000  \n",
      "NN validation MSE: 0.016142694279551506\n",
      "Saving parameters...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 2258/2258 [00:15<00:00, 143.32it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████| 103280/103280 [02:23<00:00, 719.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  prediction_reb  result_reb  prediction_total  result_total  \\\n",
      "prediction_reb          1.000000   -0.005420         -0.000337     -0.004290   \n",
      "result_reb             -0.005420    1.000000         -0.008254      0.002453   \n",
      "prediction_total       -0.000337   -0.008254          1.000000      0.028699   \n",
      "result_total           -0.004290    0.002453          0.028699      1.000000   \n",
      "prediction_score        0.936148   -0.009680         -0.018825     -0.005157   \n",
      "result_score           -0.006024    0.527572         -0.022657      0.004536   \n",
      "\n",
      "                  prediction_score  result_score  \n",
      "prediction_reb            0.936148     -0.006024  \n",
      "result_reb               -0.009680      0.527572  \n",
      "prediction_total         -0.018825     -0.022657  \n",
      "result_total             -0.005157      0.004536  \n",
      "prediction_score          1.000000     -0.011023  \n",
      "result_score             -0.011023      1.000000  \n",
      "NN validation MSE: 0.012546390295028687\n",
      "Saving parameters...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 2258/2258 [00:15<00:00, 144.10it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████| 103280/103280 [02:23<00:00, 717.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  prediction_reb  result_reb  prediction_total  result_total  \\\n",
      "prediction_reb          1.000000    0.100625         -0.008116     -0.003914   \n",
      "result_reb              0.100625    1.000000         -0.009991      0.002453   \n",
      "prediction_total       -0.008116   -0.009991          1.000000      0.030455   \n",
      "result_total           -0.003914    0.002453          0.030455      1.000000   \n",
      "prediction_score        0.976265    0.098343         -0.009853     -0.004210   \n",
      "result_score            0.131795    0.527572         -0.024690      0.004536   \n",
      "\n",
      "                  prediction_score  result_score  \n",
      "prediction_reb            0.976265      0.131795  \n",
      "result_reb                0.098343      0.527572  \n",
      "prediction_total         -0.009853     -0.024690  \n",
      "result_total             -0.004210      0.004536  \n",
      "prediction_score          1.000000      0.129933  \n",
      "result_score              0.129933      1.000000  \n",
      "NN validation MSE: 0.011602440848946571\n",
      "Saving parameters...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 2258/2258 [00:15<00:00, 141.20it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████| 103280/103280 [02:23<00:00, 721.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  prediction_reb  result_reb  prediction_total  result_total  \\\n",
      "prediction_reb          1.000000    0.124170         -0.010802     -0.002427   \n",
      "result_reb              0.124170    1.000000         -0.007786      0.002453   \n",
      "prediction_total       -0.010802   -0.007786          1.000000      0.045578   \n",
      "result_total           -0.002427    0.002453          0.045578      1.000000   \n",
      "prediction_score        0.997179    0.125005         -0.010509     -0.002449   \n",
      "result_score            0.159730    0.527572         -0.018269      0.004536   \n",
      "\n",
      "                  prediction_score  result_score  \n",
      "prediction_reb            0.997179      0.159730  \n",
      "result_reb                0.125005      0.527572  \n",
      "prediction_total         -0.010509     -0.018269  \n",
      "result_total             -0.002449      0.004536  \n",
      "prediction_score          1.000000      0.160794  \n",
      "result_score              0.160794      1.000000  \n",
      "NN validation MSE: 0.011431427672505379\n",
      "Saving parameters...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 2258/2258 [00:16<00:00, 139.77it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████| 103280/103280 [02:27<00:00, 702.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  prediction_reb  result_reb  prediction_total  result_total  \\\n",
      "prediction_reb          1.000000    0.123144         -0.011747     -0.000918   \n",
      "result_reb              0.123144    1.000000         -0.005749      0.002453   \n",
      "prediction_total       -0.011747   -0.005749          1.000000      0.043345   \n",
      "result_total           -0.000918    0.002453          0.043345      1.000000   \n",
      "prediction_score        0.989798    0.123691         -0.010587     -0.001164   \n",
      "result_score            0.153090    0.527572         -0.016254      0.004536   \n",
      "\n",
      "                  prediction_score  result_score  \n",
      "prediction_reb            0.989798      0.153090  \n",
      "result_reb                0.123691      0.527572  \n",
      "prediction_total         -0.010587     -0.016254  \n",
      "result_total             -0.001164      0.004536  \n",
      "prediction_score          1.000000      0.154446  \n",
      "result_score              0.154446      1.000000  \n",
      "NN validation MSE: 0.011510206386446953\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 2258/2258 [00:16<00:00, 137.70it/s]\n",
      " 19%|█████████████▊                                                            | 19263/103280 [00:27<02:00, 699.49it/s]\n",
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "for j in range(num_epochs):\n",
    "    network_team_ratings = {name:NetworkNode(_id, name, (torch.rand(vec_size)-0.5)*0.05) for _id, name in enumerate(teams)}\n",
    "    epoch_loss = []\n",
    "    predict_model.train()\n",
    "    update_model.train()\n",
    "    for i in tqdm(range(num_batches-1), total=num_batches-1):\n",
    "        predict_optimizer.zero_grad()\n",
    "        update_optimizer.zero_grad()\n",
    "        train_data = train[i*batch_size:(i+1)*batch_size].copy()\n",
    "        \n",
    "        t1_nodes= [network_team_ratings[team] for team in train_data.team_name.values]\n",
    "        t2_nodes= [network_team_ratings[team] for team in train_data.opp_name.values]\n",
    "        \n",
    "        distances_1 = torch.stack([(t2_nodes[i].rating-t1_nodes[i].rating) for i in range(batch_size)])\n",
    "        distances_2 = torch.stack([(t1_nodes[i].rating-t2_nodes[i].rating) for i in range(batch_size)])\n",
    "        meta_tensor = torch.from_numpy(train_data[meta].copy().astype('float32').values)\n",
    "        stat_results = torch.from_numpy(train_data[stats].copy().astype('float32').values)\n",
    "        opp_stat_results = torch.from_numpy(train_data[opp_stats].copy().astype('float32').values)\n",
    "        target_tensor = torch.from_numpy(train_data[targets].copy().astype('float32').values)\n",
    "        \n",
    "        predict_X_1 = torch.cat([distances_1, meta_tensor], axis=1)\n",
    "        predict_X_2 = torch.cat([distances_2, meta_tensor], axis=1)\n",
    "        ## in the instance of training the update model, this update X will not be used until game n+1 (need a sequence of 2 games to train update model)\n",
    "        update_X_1 = torch.cat([distances_1, meta_tensor, stat_results], axis=1)\n",
    "        update_X_2 = torch.cat([distances_2, meta_tensor, opp_stat_results], axis=1)\n",
    "        \n",
    "        update_or_predict = np.random.random()\n",
    "        \n",
    "        if update_or_predict > 0.55: # slight bias to update model, it's harder\n",
    "            ### PREDICT MODEL\n",
    "            predictions_1 = predict_model(predict_X_1)\n",
    "            predictions_2 = predict_model(predict_X_2)\n",
    "            \n",
    "            predictions = torch.mean(torch.stack([predictions_1, torch.Tensor([-1,-1,1])*predictions_2]), axis=0)\n",
    "            predict_loss = nn.MSELoss()(predictions, target_tensor)\n",
    "            predict_loss.backward()\n",
    "            # Update the model's parameters\n",
    "            ## for the first few iterations, let ratings stabilize\n",
    "            if (j>0)&(i < 20):\n",
    "                continue\n",
    "            elif (j>1)&(i < 100):\n",
    "                continue\n",
    "            else:\n",
    "                predict_optimizer.step()\n",
    "            # Zero the gradients since PyTorch accumulates them\n",
    "            predict_optimizer.zero_grad()\n",
    "        else:\n",
    "            ## UPDATE MODEL (slightly harder)\n",
    "            ## use previous game's results to calculate loss of the update model\n",
    "            ## get previous match information\n",
    "            t1_update_X = torch.stack([t1_node.get_last_update_input() for t1_node in t1_nodes])\n",
    "            t2_update_X = torch.stack([t2_node.get_last_update_input() for t2_node in t2_nodes])\n",
    "\n",
    "            t1_update_predictions = update_model(t1_update_X)\n",
    "            t2_update_predictions = update_model(t2_update_X)\n",
    "\n",
    "            ## want both baseline predict model (no update) and predict model with updates. Compare to create loss\n",
    "            baseline_X = torch.stack([t2_nodes[k].last_rating-t1_nodes[k].last_rating for k in range(len(t1_nodes))])\n",
    "            update_model_X = torch.stack([t2_nodes[k].last_rating+t2_update_predictions[k] - t1_nodes[k].last_rating+t1_update_predictions[k] for k in range(len(t1_nodes))])\n",
    "\n",
    "            ## treat this as a hypothetical prediction\n",
    "            baseline_predict_X = torch.cat([baseline_X, meta_tensor], axis=1)\n",
    "            update_predict_X = torch.cat([update_model_X, meta_tensor], axis=1)\n",
    "            ## no result above because now being used to predict *current* match\n",
    "            predict_model.eval()\n",
    "            baseline_predictions = predict_model(baseline_predict_X)\n",
    "            update_model_predictions = predict_model(update_predict_X)\n",
    "            predict_model.train()\n",
    "            baseline_MSE = nn.MSELoss()(baseline_predictions, target_tensor)\n",
    "            update_model_MSE = nn.MSELoss()(update_model_predictions, target_tensor)\n",
    "            ## lower is better, has to be negative if improving ratings\n",
    "            update_loss = update_model_MSE-baseline_MSE\n",
    "#             update_loss = nn.MSELoss()(update_model_predictions, target_tensor)\n",
    "            update_loss.backward()\n",
    "            ## skip the first few iterations of the later epochs to give some time for ratings to develop\n",
    "            if (j>0)&(i < 25):\n",
    "                continue\n",
    "            elif (j>1)&(i < 100):\n",
    "                continue\n",
    "            else:\n",
    "                update_optimizer.step()\n",
    "            update_optimizer.zero_grad()\n",
    "            \n",
    "        ### NOW ACTUALLY UPDATE\n",
    "        ## since this is n, n+1 instead of n-1, n: we can use the update model we just backprop'd\n",
    "        for i in range(len(t1_nodes)):\n",
    "            t1 = t1_nodes[i]\n",
    "            t2 = t2_nodes[i]\n",
    "            update_model.eval()\n",
    "            update_pred_1 = update_model(update_X_1[i])\n",
    "            update_pred_2 = update_model(update_X_2[i])\n",
    "            update_model.train()\n",
    "            node_update = torch.mean(torch.stack([update_pred_1, -1*update_pred_2]), axis=0)\n",
    "            t1.last_rating = t1.rating.detach().clone()\n",
    "            t2.last_rating = t2.rating.detach().clone()\n",
    "            # Update ratings without in-place operation\n",
    "            t1.rating = t1.rating.detach().clone() + node_update.detach().clone()\n",
    "            t2.rating = t2.rating.detach().clone() + node_update.detach().clone()\n",
    "            t1.last_vector = update_X_1[i].detach().clone()\n",
    "            t2.last_vector = update_X_2[i].detach().clone()\n",
    "\n",
    "            network_team_ratings[t1.name] = copy(t1)\n",
    "            network_team_ratings[t2.name] = copy(t2)    \n",
    "\n",
    "    ## find test error\n",
    "    ## calculate val\n",
    "    predict_model.eval()\n",
    "    update_model.eval()\n",
    "    \n",
    "    network_team_ratings = {name:NetworkNode(_id, name, (torch.rand(vec_size)-0.5)*0.05) for _id, name in enumerate(teams)}\n",
    "    nn_history = []\n",
    "    ### have to go one game at a time\n",
    "    for index, row in tqdm(data.iterrows(), total=len(data)):\n",
    "\n",
    "        t1_id, t2_id = row['team_name'], row['opp_name']\n",
    "        \n",
    "        t1_nn_node = network_team_ratings[t1_id]\n",
    "        t2_nn_node = network_team_ratings[t2_id]\n",
    "\n",
    "        distance_1 = t2_nn_node.rating-t1_nn_node.rating\n",
    "        distance_2 = t1_nn_node.rating-t2_nn_node.rating\n",
    "        meta_tensor = torch.from_numpy(row[meta].copy().astype('float32').values)\n",
    "        stat_results = torch.from_numpy(row[stats].copy().astype('float32').values)\n",
    "        opp_stat_results = torch.from_numpy(row[opp_stats].copy().astype('float32').values)\n",
    "        target_tensor = torch.from_numpy(row[targets].copy().astype('float32').values)\n",
    "\n",
    "        nn_prediction_1 = predict_model(torch.cat([distance_1, meta_tensor]))\n",
    "        nn_prediction_2 = predict_model(torch.cat([distance_2, meta_tensor]))\n",
    "        \n",
    "        nn_prediction = torch.mean(torch.stack([nn_prediction_1, torch.Tensor([-1,-1,1])*nn_prediction_2]), axis=0)\n",
    "        error = target_tensor - nn_prediction\n",
    "        \n",
    "        p1_update_X = torch.cat([distance_1, meta_tensor, stat_results]).float()\n",
    "        p2_update_X = torch.cat([distance_2, meta_tensor, opp_stat_results]).float()\n",
    "        \n",
    "        p1_rtg_update = update_model(p1_update_X)\n",
    "        p2_rtg_update = update_model(p2_update_X)\n",
    "        rtg_update = torch.mean(torch.stack([p1_rtg_update, -1*p2_rtg_update]),axis=0)\n",
    "        \n",
    "        id_data = [t1_nn_node._id, t1_nn_node.name, t2_nn_node._id, t2_nn_node.name]\n",
    "        torch_data = torch.cat([t1_nn_node.rating.detach().clone(), t2_nn_node.rating.detach().clone(), nn_prediction.detach().clone(), target_tensor.detach().clone(), rtg_update.detach().clone()])\n",
    "        id_data.extend(list(torch_data.detach().numpy()))\n",
    "        nn_history.append(id_data)\n",
    "        t1_nn_node.last_rating = t1_nn_node.rating.detach().clone()\n",
    "        t2_nn_node.last_rating = t2_nn_node.rating.detach().clone()\n",
    "        t1_nn_node.rating = t1_nn_node.rating.detach().clone() + rtg_update.detach().clone()\n",
    "        t2_nn_node.rating = t2_nn_node.rating.detach().clone() + rtg_update.detach().clone()\n",
    "        network_team_ratings[t1_id] = copy(t1_nn_node)\n",
    "        network_team_ratings[t2_id] = copy(t2_nn_node)\n",
    "\n",
    "    nn_hist = pd.DataFrame(nn_history, columns=['p1_id','p1_name','p2_id','p2_name',\n",
    "                                                'p1_rating_x','p1_rating_y','p1_rating_z',\n",
    "                                                'p2_rating_x','p2_rating_y','p2_rating_z',\n",
    "                                                'prediction_score','prediction_reb','prediction_total',\n",
    "                                                'result_score','result_reb','result_total',\n",
    "                                                'ratings_delta_x','ratings_delta_y','ratings_delta_z'])\n",
    "    \n",
    "    print(nn_hist[['prediction_reb','result_reb','prediction_total','result_total','prediction_score','result_score']].corr())\n",
    "    \n",
    "    val_loss = mean_squared_error(nn_hist[-grade_cutoff:]['result_score'].values, nn_hist[-grade_cutoff:]['prediction_score'].values)\n",
    "    print(f\"NN validation MSE: {val_loss}\")\n",
    "    \n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        print(\"Saving parameters...\")\n",
    "        torch.save(predict_model.state_dict(), 'pairwise_predict_nn_best_model.pth')\n",
    "        torch.save(update_model.state_dict(), 'pairwise_update_nn_best_model.pth')\n",
    "            \n",
    "            \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba8f57c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "sns.displot(nn_hist.prediction_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "818583be",
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_hist[['prediction_score','result_score']].corr()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7f7357b",
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_hist[['prediction_reb','result_reb','prediction_total','result_total','prediction_score','result_score']].corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07dd2f64",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(nn_hist.result_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2851e06",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(nn_hist.prediction_total)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43f665ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "nn_hist\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "805ac389",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
