{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from tqdm import tqdm\n",
    "from scipy import sparse\n",
    "from datetime import datetime\n",
    "from scipy.linalg import solve\n",
    "from scipy.optimize import minimize\n",
    "from scipy.sparse.linalg import spsolve\n",
    "from bayes_opt import BayesianOptimization\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "DATA_PATH = '../data/testing/ncaam_sample_data.csv'\n",
    "def load_data(data_path):\n",
    "    return pd.read_csv(data_path)\n",
    "\n",
    "m_data = load_data(DATA_PATH)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Optimizer:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def optimize(self):\n",
    "        raise NotImplementedError(\"Subclasses must implement the optimize method.\")\n",
    "\n",
    "\n",
    "class MasseyOptimizer(Optimizer):\n",
    "    def __init__(self, decay_type, protag_col='team', antag_col='opponent', stat_col='team_sq_score', meta_cols=['location'], min_protag_games=5):\n",
    "        super().__init__()\n",
    "        assert(decay_type in ['time', 'games','both'])\n",
    "        self.decay_type = decay_type\n",
    "        self.protag_col = protag_col\n",
    "        self.antag_col = antag_col\n",
    "        self.stat_col = stat_col\n",
    "        self.meta_cols = meta_cols\n",
    "        self.min_protag_games = min_protag_games\n",
    "\n",
    "    def load_data(self, data, path=None):\n",
    "        if path is not None:\n",
    "            self.data = pd.read_csv(path)\n",
    "        else:\n",
    "            self.data = data\n",
    "        self.preprocess_data()\n",
    "\n",
    "    def preprocess_data(self):\n",
    "\n",
    "        assert(self.protag_col in self.data.columns), \"Protagonist column not found in data\"\n",
    "        assert(self.antag_col in self.data.columns), \"Antagonist column not found in data\"\n",
    "        assert(self.stat_col in self.data.columns), \"Stat column not found in data\"\n",
    "        \n",
    "        # Convert date column to datetime if needed\n",
    "        if isinstance(self.data['date'].iloc[0], str):\n",
    "            self.data['date'] = pd.to_datetime(self.data['date'])\n",
    "\n",
    "        # Sort data by date\n",
    "        self.data = self.data.sort_values('date').reset_index(drop=True)\n",
    "\n",
    "        # Create a team/player list\n",
    "        self.protags = list(self.data[self.protag_col].unique())\n",
    "        self.antags = list(self.data[self.antag_col].unique())\n",
    "        self.protags = sorted(self.protags)\n",
    "        self.antags = sorted(self.antags)\n",
    "\n",
    "        self.num_protags = len(self.protags)\n",
    "        self.num_antags = len(self.antags)\n",
    "\n",
    "        self.data['protag_idx'] = self.data[self.protag_col].apply(lambda x: self.protags.index(x))\n",
    "        self.data['antag_idx'] = self.data[self.antag_col].apply(lambda x: self.antags.index(x))\n",
    "\n",
    "        assert(len(self.data)>200), \"Not enough data to optimize\"\n",
    "\n",
    "    def initialize_X_train(self, train):\n",
    "\n",
    "        protags = sorted(train[self.protag_col].unique())\n",
    "        antags = sorted(train[self.antag_col].unique())\n",
    "        num_train_protags = len(protags)\n",
    "        num_train_antags = len(antags)\n",
    "\n",
    "        train['protag_idx'] = train[self.protag_col].apply(lambda x: protags.index(x))\n",
    "        train['antag_idx'] = train[self.antag_col].apply(lambda x: antags.index(x))\n",
    "\n",
    "        X_train = np.zeros((len(train), num_train_protags+num_train_antags+len(self.meta_cols)))\n",
    "        X_train[np.arange(len(train)), train['protag_idx']] = 1\n",
    "        X_train[np.arange(len(train)), train['antag_idx']+num_train_protags] = 1\n",
    "        for i, col in enumerate(self.meta_cols):\n",
    "            X_train[np.arange(len(train)), -1*i] = train[col]\n",
    "        \n",
    "        X_train = sparse.csr_matrix(X_train)\n",
    "        return X_train, protags, antags\n",
    "\n",
    "    def initialize_X_test(self, test, protags, antags):\n",
    "\n",
    "        num_protags = len(protags)\n",
    "        num_antags = len(antags)\n",
    "        test['protag_idx'] = test[self.protag_col].apply(lambda x: protags.index(x) if x in protags else num_protags)\n",
    "        test['antag_idx'] = test[self.antag_col].apply(lambda x: antags.index(x) if x in antags else num_antags)\n",
    "        test = test.loc[test['protag_idx']<num_protags]\n",
    "        test = test.loc[test['antag_idx']<num_antags]\n",
    "        test_idx = test.index.values\n",
    "        test = test.reset_index(drop=True)\n",
    "        X_test = np.zeros((len(test), len(protags)+len(antags)+len(self.meta_cols)))\n",
    "        X_test[np.arange(len(test)), test['protag_idx']] = 1\n",
    "        X_test[np.arange(len(test)), test['antag_idx']+num_protags+1] = 1\n",
    "\n",
    "        for i, col in enumerate(self.meta_cols):\n",
    "            X_test[np.arange(len(test)), -1*i] = test[col]\n",
    "\n",
    "        X_test = sparse.csr_matrix(X_test)\n",
    "\n",
    "        return X_test, test_idx\n",
    "\n",
    "    def run_time_opt(self, init_points=10, n_iter=30, num_test_dates=20, num_future_days=60, max_lookback=365*3, halflife_bounds=(10, 800), l2_bounds=(1e-9, 10)):#offense_halflife_bounds=(50, 800), defense_halflife_bounds=(50,800), meta_halflife_bounds=(100,800), l2_bounds=(1e-8, 1)):\n",
    "\n",
    "        # Select random test dates\n",
    "        unique_dates = self.data['date'].unique()\n",
    "        ## don't take from the first 10 or so dates\n",
    "        unique_dates = sorted(unique_dates)[10:]\n",
    "        \n",
    "        test_dates = np.random.choice(unique_dates, size=num_test_dates, replace=False)\n",
    "        num_dates = len(unique_dates)\n",
    "\n",
    "        for test_date in test_dates:\n",
    "            train_data = self.data[(self.data['date'] >= test_date - pd.Timedelta(days=max_lookback)) & (self.data['date'] < test_date)].copy()\n",
    "            test_data = self.data[(self.data['date'] >= test_date) & (self.data['date'] <= test_date + pd.Timedelta(days=num_future_days))].copy()\n",
    "            if len(train_data) < 50 or len(test_data) < 50:\n",
    "                print(\"Not enough data for test date\", test_date)\n",
    "                test_dates = np.delete(test_dates, np.where(test_dates==test_date))\n",
    "\n",
    "        def time_bayes_objective(halflife, l2):\n",
    "\n",
    "            decay = np.exp(-np.log(2)/halflife)\n",
    "\n",
    "            for i, test_date in enumerate(test_dates):\n",
    "\n",
    "                # Filter data before the given date\n",
    "                X_train = self.data[(self.data['date'] >= test_date - pd.Timedelta(days=max_lookback)) & (self.data['date'] < test_date)].copy()\n",
    "                idx = X_train.index.values\n",
    "                if len(X_train) < 50:\n",
    "                    print(\"Minimum data threshold not met\")\n",
    "                    continue\n",
    "                X_train, protags, antags = self.initialize_X_train(X_train)\n",
    "                num_protags = len(protags)\n",
    "                num_antags = len(antags)\n",
    "                X_test = self.data[(self.data['date'] >= test_date) & (self.data['date'] <= test_date + pd.Timedelta(days=num_future_days))].dropna(subset=[self.stat_col]).copy()\n",
    "\n",
    "                if X_train.shape[0] < 50 or len(X_test) < 50:\n",
    "                    continue\n",
    "\n",
    "                dw = decay ** ((test_date - pd.to_datetime(self.data.iloc[idx]['date'])).astype('timedelta64[D]').astype(int))\n",
    "                dw = dw.values.reshape(-1)\n",
    "                dw = dw/np.sum(dw)\n",
    "\n",
    "                # Calculate the time differences in days between each game and the most recent game\n",
    "                W = sparse.diags(dw)\n",
    "                \n",
    "                q = (X_train.T @ W @ X_train).toarray()\n",
    "                q += l2 * np.eye(q.shape[0]) * np.trace(q) / q.shape[0]\n",
    "\n",
    "                y = self.data.loc[idx, self.stat_col].values\n",
    "                f = X_train.T @ W @ y\n",
    "\n",
    "                # Calculate the exponential decay weights based on the time differences and half-lives\n",
    "                # solution\n",
    "                b = solve(q, f, assume_a='pos')\n",
    "\n",
    "                # Split the ratings into offense and defense ratings\n",
    "                offense_ratings = b[:num_protags]\n",
    "                defense_ratings = b[num_protags:num_protags+num_antags]\n",
    "\n",
    "                offense_df = pd.DataFrame({\n",
    "                    self.protag_col: protags,\n",
    "                    'offense_rating': offense_ratings\n",
    "                })\n",
    "                defense_df = pd.DataFrame({\n",
    "                    self.antag_col: antags,\n",
    "                    'defense_rating': defense_ratings\n",
    "                })\n",
    "                \n",
    "\n",
    "                # X_test, test_idx = self.initialize_X_test(X_test, protags, antags)\n",
    "                test_idx = X_test.index.values\n",
    "                \n",
    "                X_test = X_test.merge(offense_df, on=self.protag_col, how='left')\n",
    "                X_test = X_test.merge(defense_df, on=self.antag_col, how='left')\n",
    "                # print(test_data.head())\n",
    "                X_test = X_test.dropna(subset=['offense_rating','defense_rating'])\n",
    "                y_test = X_test[self.stat_col]\n",
    "\n",
    "                if len(X_test) <10:\n",
    "                    print(\"Not enough data for test date\", test_date)\n",
    "                    continue\n",
    "                \n",
    "                # Calculate the predicted scores\n",
    "                linear_model = LinearRegression()\n",
    "                predictions = cross_val_predict(linear_model, X_test[['offense_rating','defense_rating']], y_test, cv=5)\n",
    "                X_test['pred_score'] = predictions\n",
    "                X_test['mse'] = (X_test[self.stat_col] - X_test['pred_score']) ** 2\n",
    "                mse = X_test['mse'].mean()\n",
    "\n",
    "            return -mse  \n",
    "        \n",
    "        best_decay_factor = None\n",
    "        best_l2 = None\n",
    "        best_mse = None\n",
    "\n",
    "        pbounds = {'halflife': halflife_bounds, 'l2': l2_bounds}\n",
    "        # pbounds = {'offense_halflife': offense_halflife_bounds, 'defense_halflife': defense_halflife_bounds, 'meta_halflife':meta_halflife_bounds, 'l2': l2_bounds}\n",
    "       \n",
    "        # Initialize the Bayesian Optimization object\n",
    "        optimizer = BayesianOptimization(f=time_bayes_objective, pbounds=pbounds, random_state=17)\n",
    "\n",
    "        # Perform the optimization\n",
    "        optimizer.maximize(init_points=init_points, n_iter=n_iter)\n",
    "        \n",
    "        # Get the best parameters and correlation\n",
    "        best_params = optimizer.max['params']\n",
    "        best_halflife = best_params['halflife']\n",
    "        best_l2 = best_params['l2']\n",
    "        best_mse = -optimizer.max['target']\n",
    "\n",
    "        return best_halflife, best_l2, best_mse\n",
    "\n",
    "    def run_full_time_opt(self, num_samples=25, num_test_dates=20, num_future_days=60, max_lookback=365*2, halflife_bounds=(50, 800), l2_bounds=(1e-8, 1)):\n",
    "\n",
    "        optimal_halflifes = []\n",
    "        optimal_l2s = []\n",
    "        best_mses = []\n",
    "        for i in tqdm(range(num_samples), total=num_samples):\n",
    "            best_halflife, best_l2, best_mse = self.run_time_opt_scipy(13, 32, num_test_dates, num_future_days, max_lookback, halflife_bounds, l2_bounds)\n",
    "\n",
    "            optimal_halflifes.append(best_halflife)\n",
    "            optimal_l2s.append(best_l2)\n",
    "            best_mses.append(best_mse)\n",
    "        return optimal_halflifes, optimal_l2s, best_mses\n",
    "\n",
    "\n",
    "    def get_ratings_for_dates(self, dates, halflife, l2, max_lookback=365*2.1):\n",
    "        \n",
    "        num_dates = len(dates)\n",
    "\n",
    "        decay = np.exp(-np.log(2)/halflife)\n",
    "        offense_stats = []\n",
    "        defense_stats = []\n",
    "        meta_stats = []\n",
    "        # dates = [pd.to_datetime('04-09-2024')]\n",
    "        for i, date in tqdm(enumerate(dates), total=num_dates):\n",
    "\n",
    "                # Filter data before the given date\n",
    "            X_train = self.data[(self.data['date'] >= date - pd.Timedelta(days=max_lookback)) & (self.data['date'] < date)].copy()\n",
    "            idx = X_train.index.values\n",
    "            if len(X_train) < 50:\n",
    "                print(\"Minimum data threshold not met\")\n",
    "                continue\n",
    "            X_train, protags, antags = self.initialize_X_train(X_train)\n",
    "            num_protags = len(protags)\n",
    "            num_antags = len(antags)\n",
    "\n",
    "            # Filter data before the given date\n",
    "            time_date = pd.to_datetime(date) \n",
    "            temp = time_date - pd.to_datetime(self.data.iloc[idx]['date'])\n",
    "            dw = decay ** (temp.astype('timedelta64[D]').astype(int))\n",
    "            dw = dw.values.reshape(-1)\n",
    "            dw = dw/np.sum(dw)\n",
    "\n",
    "            # Calculate the time differences in days between each game and the most recent game\n",
    "            W = sparse.diags(dw)\n",
    "            \n",
    "            q = (X_train.T @ W @ X_train).toarray()\n",
    "            q += l2 * np.eye(q.shape[0]) * np.trace(q) / q.shape[0]\n",
    "\n",
    "            y = self.data.iloc[idx][self.stat_col].values\n",
    "            f = X_train.T @ W @ y\n",
    "            # Calculate the exponential decay weights based on the time differences and half-lives\n",
    "            # solution\n",
    "            b = solve(q, f, assume_a='pos')\n",
    "\n",
    "            # Split the ratings into offense and defense ratings\n",
    "            offense_ratings = b[:num_protags]\n",
    "            defense_ratings = b[num_protags:num_protags+num_antags]\n",
    "            meta_ratings = b[num_protags+num_antags:]\n",
    "\n",
    "\n",
    "            # Create DataFrames for offense ratings and defense ratings\n",
    "            offense_stat = pd.DataFrame({\n",
    "                'protag': protags,\n",
    "                self.stat_col: offense_ratings\n",
    "            })\n",
    "            offense_stat['date'] = date\n",
    "            defense_stat = pd.DataFrame({\n",
    "                'antag': antags,\n",
    "                self.stat_col: defense_ratings\n",
    "            })\n",
    "            defense_stat['date'] = date\n",
    "            meta_ratings = pd.DataFrame({\n",
    "                'meta': self.meta_cols,\n",
    "                self.stat_col: meta_ratings\n",
    "            })\n",
    "\n",
    "            offense_stats.append(offense_stat)\n",
    "            defense_stats.append(defense_stat)\n",
    "            meta_stats.append(meta_ratings)\n",
    "\n",
    "        offense_stats = pd.concat(offense_stats).reset_index(drop=True)\n",
    "        defense_stats = pd.concat(defense_stats).reset_index(drop=True)\n",
    "\n",
    "        return offense_stats, defense_stats\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>season</th>\n",
       "      <th>team_score</th>\n",
       "      <th>opp_score</th>\n",
       "      <th>is_home</th>\n",
       "      <th>numot</th>\n",
       "      <th>team_fgm</th>\n",
       "      <th>team_fga</th>\n",
       "      <th>team_fgm3</th>\n",
       "      <th>team_fga3</th>\n",
       "      <th>team_ftm</th>\n",
       "      <th>...</th>\n",
       "      <th>opp_or</th>\n",
       "      <th>opp_dr</th>\n",
       "      <th>opp_ast</th>\n",
       "      <th>opp_to</th>\n",
       "      <th>opp_stl</th>\n",
       "      <th>opp_blk</th>\n",
       "      <th>opp_pf</th>\n",
       "      <th>team_name</th>\n",
       "      <th>opp_name</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2003</td>\n",
       "      <td>68</td>\n",
       "      <td>62</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "      <td>58</td>\n",
       "      <td>3</td>\n",
       "      <td>14</td>\n",
       "      <td>11</td>\n",
       "      <td>...</td>\n",
       "      <td>10</td>\n",
       "      <td>22</td>\n",
       "      <td>8</td>\n",
       "      <td>18</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>Oklahoma</td>\n",
       "      <td>2002-11-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2003</td>\n",
       "      <td>70</td>\n",
       "      <td>63</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>26</td>\n",
       "      <td>62</td>\n",
       "      <td>8</td>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>20</td>\n",
       "      <td>25</td>\n",
       "      <td>7</td>\n",
       "      <td>12</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>16</td>\n",
       "      <td>Memphis</td>\n",
       "      <td>Syracuse</td>\n",
       "      <td>2002-11-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2003</td>\n",
       "      <td>62</td>\n",
       "      <td>68</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>53</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>16</td>\n",
       "      <td>...</td>\n",
       "      <td>14</td>\n",
       "      <td>24</td>\n",
       "      <td>13</td>\n",
       "      <td>23</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>Oklahoma</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>2002-11-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2003</td>\n",
       "      <td>63</td>\n",
       "      <td>70</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>67</td>\n",
       "      <td>6</td>\n",
       "      <td>24</td>\n",
       "      <td>9</td>\n",
       "      <td>...</td>\n",
       "      <td>15</td>\n",
       "      <td>28</td>\n",
       "      <td>16</td>\n",
       "      <td>13</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>18</td>\n",
       "      <td>Syracuse</td>\n",
       "      <td>Memphis</td>\n",
       "      <td>2002-11-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2003</td>\n",
       "      <td>55</td>\n",
       "      <td>81</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>46</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>12</td>\n",
       "      <td>...</td>\n",
       "      <td>12</td>\n",
       "      <td>24</td>\n",
       "      <td>12</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>18</td>\n",
       "      <td>E Washington</td>\n",
       "      <td>Wisconsin</td>\n",
       "      <td>2002-11-15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   season  team_score  opp_score  is_home  numot  team_fgm  team_fga  \\\n",
       "0    2003          68         62        0      0        27        58   \n",
       "1    2003          70         63        0      0        26        62   \n",
       "2    2003          62         68        0      0        22        53   \n",
       "3    2003          63         70        0      0        24        67   \n",
       "4    2003          55         81       -1      0        20        46   \n",
       "\n",
       "   team_fgm3  team_fga3  team_ftm  ...  opp_or  opp_dr  opp_ast  opp_to  \\\n",
       "0          3         14        11  ...      10      22        8      18   \n",
       "1          8         20        10  ...      20      25        7      12   \n",
       "2          2         10        16  ...      14      24       13      23   \n",
       "3          6         24         9  ...      15      28       16      13   \n",
       "4          3         11        12  ...      12      24       12       9   \n",
       "\n",
       "   opp_stl  opp_blk  opp_pf     team_name   opp_name       date  \n",
       "0        9        2      20       Alabama   Oklahoma 2002-11-14  \n",
       "1        8        6      16       Memphis   Syracuse 2002-11-14  \n",
       "2        7        1      22      Oklahoma    Alabama 2002-11-14  \n",
       "3        4        4      18      Syracuse    Memphis 2002-11-14  \n",
       "4        9        3      18  E Washington  Wisconsin 2002-11-15  \n",
       "\n",
       "[5 rows x 34 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "MO = MasseyOptimizer('time', protag_col='team_name', antag_col='opp_name', stat_col='team_score', meta_cols=['is_home'])\n",
    "MO.load_data(m_data)\n",
    "# halflife, l2, mse = MO.run_time_opt()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/135 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "matrix - rhs dimension mismatch ((715, 715) - 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[39], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m rating_dates \u001b[38;5;241m=\u001b[39m [date \u001b[38;5;28;01mfor\u001b[39;00m date \u001b[38;5;129;01min\u001b[39;00m m_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdate\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39munique() \u001b[38;5;28;01mif\u001b[39;00m date \u001b[38;5;241m>\u001b[39m pd\u001b[38;5;241m.\u001b[39mto_datetime(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m2021-10-01\u001b[39m\u001b[38;5;124m'\u001b[39m)]\n\u001b[1;32m----> 2\u001b[0m offense_ratings, defense_ratings \u001b[38;5;241m=\u001b[39m MO\u001b[38;5;241m.\u001b[39mget_ratings_for_dates(rating_dates, halflife, l2)\n",
      "Cell \u001b[1;32mIn[36], line 252\u001b[0m, in \u001b[0;36mMasseyOptimizer.get_ratings_for_dates\u001b[1;34m(self, dates, halflife, l2, max_lookback)\u001b[0m\n\u001b[0;32m    249\u001b[0m f \u001b[38;5;241m=\u001b[39m X_train\u001b[38;5;241m.\u001b[39mT \u001b[38;5;241m@\u001b[39m W \u001b[38;5;241m@\u001b[39m y\n\u001b[0;32m    250\u001b[0m \u001b[38;5;66;03m# Calculate the exponential decay weights based on the time differences and half-lives\u001b[39;00m\n\u001b[0;32m    251\u001b[0m \u001b[38;5;66;03m# solution\u001b[39;00m\n\u001b[1;32m--> 252\u001b[0m b \u001b[38;5;241m=\u001b[39m spsolve(sparse\u001b[38;5;241m.\u001b[39mcsr_matrix(q), sparse\u001b[38;5;241m.\u001b[39mcsr_matrix(f))\n\u001b[0;32m    254\u001b[0m \u001b[38;5;66;03m# Split the ratings into offense and defense ratings\u001b[39;00m\n\u001b[0;32m    255\u001b[0m offense_ratings \u001b[38;5;241m=\u001b[39m b[:num_protags]\n",
      "File \u001b[1;32mc:\\Users\\Blake\\anaconda3\\Lib\\site-packages\\scipy\\sparse\\linalg\\_dsolve\\linsolve.py:238\u001b[0m, in \u001b[0;36mspsolve\u001b[1;34m(A, b, permc_spec, use_umfpack)\u001b[0m\n\u001b[0;32m    235\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmatrix must be square (has shape \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m ((M, N),))\n\u001b[0;32m    237\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m M \u001b[38;5;241m!=\u001b[39m b\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]:\n\u001b[1;32m--> 238\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmatrix - rhs dimension mismatch (\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m - \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    239\u001b[0m                      \u001b[38;5;241m%\u001b[39m (A\u001b[38;5;241m.\u001b[39mshape, b\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]))\n\u001b[0;32m    241\u001b[0m use_umfpack \u001b[38;5;241m=\u001b[39m use_umfpack \u001b[38;5;129;01mand\u001b[39;00m useUmfpack\n\u001b[0;32m    243\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m b_is_vector \u001b[38;5;129;01mand\u001b[39;00m use_umfpack:\n",
      "\u001b[1;31mValueError\u001b[0m: matrix - rhs dimension mismatch ((715, 715) - 1)"
     ]
    }
   ],
   "source": [
    "rating_dates = [date for date in m_data['date'].unique() if date > pd.to_datetime('2021-10-01')]\n",
    "offense_ratings, defense_ratings = MO.get_ratings_for_dates(rating_dates, halflife, l2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>protag</th>\n",
       "      <th>team_score</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Abilene Chr</td>\n",
       "      <td>1.256678</td>\n",
       "      <td>2021-11-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Air Force</td>\n",
       "      <td>-9.278845</td>\n",
       "      <td>2021-11-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Akron</td>\n",
       "      <td>3.565941</td>\n",
       "      <td>2021-11-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>12.833932</td>\n",
       "      <td>2021-11-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Alabama A&amp;M</td>\n",
       "      <td>-14.621407</td>\n",
       "      <td>2021-11-09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        protag  team_score       date\n",
       "0  Abilene Chr    1.256678 2021-11-09\n",
       "1    Air Force   -9.278845 2021-11-09\n",
       "2        Akron    3.565941 2021-11-09\n",
       "3      Alabama   12.833932 2021-11-09\n",
       "4  Alabama A&M  -14.621407 2021-11-09"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "offense_ratings.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
